<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jon Barron</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jon Barron
                </p>
                <p>I'm a research scientist at <a href="https://deepmind.google/">Google DeepMind</a> in San Francisco, where I lead a small team that mostly works on <a href="https://www.matthewtancik.com/nerf">NeRF</a>.
                </p>
                <p>
                  At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">VR</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://blog.google/products/maps/three-maps-updates-io-2022/">Maps</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I've received the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jonbarron/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }

          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://cat3d.github.io/">
			<span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models
</span>
        </a>
        <br>
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
        <a href="https://holynski.org/">Aleksander Holynski</a>*, 
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>, 
				<a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>, 
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://poolio.github.io/">Ben Poole</a>*

        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
        <p></p>
        <p>
				A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
        </p>
      </td>
    </tr>


    <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bog_image'><video  width=100% muted autoplay loop>
          <source src="images/bog.jpg" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/bog.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('bog_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('bog_image').style.opacity = "0";
          }
          bog_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://creiser.github.io/binary_opacity_grid/">
          <span class="papertitle">Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis
</span>
        </a>
        <br>
				<a href="https://creiser.github.io/">Christian Reiser</a>,
				<a href="http://stephangarbin.com/">Stephan J. Garbin</a>,
				<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
				<a href="https://dorverbin.github.io/">Dor Verbin</a>,
				<a href="https://szeliski.org/RichardSzeliski.htm">Richard Szeliski</a>,
				<a href="https://bmild.github.io/">Ben Mildenhall</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://phogzone.com/">Peter Hedman</a>*,
				<a href="https://www.cvlibs.net/">Andreas Geiger</a>*		
        <br>
        <em>SIGGRAPH</em>, 2024
        <br>
        <a href="https://creiser.github.io/binary_opacity_grid/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=2TPUmGRg8bM">video</a>
        /
        <a href="https://arxiv.org/abs/2402.12377">arXiv</a>
        <p></p>
        <p>
        Applying anti-aliasing to a discrete opacity grid lets you render a hard representation into a soft image, and this enables highly-detailed mesh recovery.
        </p>
      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
          <source src="images/smerf.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/smerf.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function smerf_start() {
            document.getElementById('smerf_image').style.opacity = "1";
          }

          function smerf_stop() {
            document.getElementById('smerf_image').style.opacity = "0";
          }
          smerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>
        <br>
		<a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>,
		<a href="https://phogzone.com/">Peter Hedman*</a>,
		<a href="https://creiser.github.io/">Christian Reiser</a>,
		<a href="">Peter Zhizhin</a>,
		<a href="">Jean-François Thibert</a>,
        <a href="https://lucic.ai/">Mario Lučić</a>,
        <a href="https://szeliski.org/">Richard Szeliski</a>,
		<strong>Jonathan T. Barron</strong>
        <br>
        <em>SIGGRAPH</em>, 2024 &nbsp <font color="red"><strong>(Honorable Mention)</strong></font>
        <br>
        <a href="https://smerf-3d.github.io/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
      </td>
    </tr>
	

   
            <tr onmouseout="winr_stop()" onmouseover="winr_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='winr_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/notre_160.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/notre.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function winr_start() {
                    document.getElementById('winr_image').style.opacity = "1";
                  }
                  function winr_stop() {
                    document.getElementById('winr_image').style.opacity = "0";
                  }
                  winr_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://www.matthewtancik.com/learnit">
                  <span class="papertitle">Learned Initializations for Optimizing Coordinate-Based Neural Representations</span>
                </a>
                <br>
                <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
                <a href="https://bmild.github.io/">Ben Mildenhall*</a>,
                <a href="https://www.linkedin.com/in/terrance-wang/">Terrance Wang</a>,
                <a href="https://www.linkedin.com/in/divi-schmidt-262044180/">Divi Schmidt</a>, <br>
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
                <br>
                <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="http://www.matthewtancik.com/learnit">project page</a> /
                <a href="https://www.youtube.com/watch?v=A-r9itCzcyo">video</a> /
                <a href="https://arxiv.org/abs/2012.02189">arXiv</a> 
                <p></p>
                <p>Using meta-learning to find weight initializations for coordinate-based MLPs allows them to converge faster and generalize better.</p>
              </td>
            </tr>

            <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='nerfw_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/nerfw_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/nerfw_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function nerfw_start() {
                    document.getElementById('nerfw_image').style.opacity = "1";
                  }

                  function nerfw_stop() {
                    document.getElementById('nerfw_image').style.opacity = "0";
                  }
                  nerfw_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://nerf-w.github.io/">
                  <span class="papertitle">NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</span>
                </a>
                <br>
                <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla*</a>,
                <a href="https://scholar.google.com/citations?user=g98QcZUAAAAJ&hl=en">Noha Radwan*</a>,
                <a href="https://research.google/people/105804/">Mehdi S. M. Sajjadi*</a>, <br>
                <strong>Jonathan T. Barron</strong>,
                <a href="https://scholar.google.com/citations?user=FXNJRDoAAAAJ&hl=en">Alexey Dosovitskiy</a>,
                <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth</a>
                <br>
                <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://nerf-w.github.io/">project page</a> /
                <a href="https://arxiv.org/abs/2008.02268">arXiv</a> /
                <a href="https://www.youtube.com/watch?v=mRAKVQj5LRA">video</a>
                <p></p>
                <p>Letting NeRF reason about occluders and appearance variation produces photorealistic view synthesis using only unstructured internet photos.</p>
              </td>
            </tr> 

            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualrefl_image'>
                    <img src='images/dualrefl_after.jpg' width="160"></div>
                  <img src='images/dualrefl_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dualrefl_start() {
                    document.getElementById('dualrefl_image').style.opacity = "1";
                  }

                  function dualrefl_stop() {
                    document.getElementById('dualrefl_image').style.opacity = "0";
                  }
                  dualrefl_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://sniklaus.com/dualref">
                  <span class="papertitle">Learned Dual-View Reflection Removal</span>
                </a>
                <br>
                <a href="http://sniklaus.com/welcome">Simon Niklaus</a>,
                <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
                <strong>Jonathan T. Barron</strong>, <br>
                <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
                <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
                <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a>,
                <a href="https://tianfan.info/">Tianfan Xue</a>
                <br>
                <em>WACV</em>, 2021
                <br>
                <a href="http://sniklaus.com/dualref">project page</a> /
                <a href="https://arxiv.org/abs/2010.00702">arXiv</a>
                <p></p>
                <p>
                  Reflections and the things behind them often exhibit parallax, and this lets you remove reflections from stereo pairs.
                </p>
              </td>
            </tr> 



            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 135, 2008
                <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
                <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
              </td>
            </tr>

          </tbody></table>

          
          <table width="100%" align="Left" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
	I enjoy playing badminton and competing in various tournaments in my spare time. If you're good at it and are in or near Oregon, please feel free to contact me and join in.				
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Thank you to <a href="https://jonbarron.info/">Jon Barron</a> for the website template.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
